{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f3defff-624e-4390-96a3-32380cc070e1",
   "metadata": {},
   "source": [
    "# Titanic_Survival_Competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbbcaa9e-671d-4780-a621-78ee79484019",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library Imports: \n",
    "\n",
    "#DataFrame operation: \n",
    "import pandas as pd\n",
    "\n",
    "#preproccecing: \n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a7e0435-4059-4d32-a660-7c4347071202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train columns:  Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object') \n",
      "\n",
      "**Columns with Missing values of Training Set: \n",
      "(PassengerId): missing values: 0\n",
      "(Survived): missing values: 0\n",
      "(Pclass): missing values: 0\n",
      "(Name): missing values: 0\n",
      "(Sex): missing values: 0\n",
      "(Age): missing values: 177\n",
      "(SibSp): missing values: 0\n",
      "(Parch): missing values: 0\n",
      "(Ticket): missing values: 0\n",
      "(Fare): missing values: 0\n",
      "(Cabin): missing values: 687\n",
      "(Embarked): missing values: 2\n",
      "**Columns with Missing values of Test Set: \n",
      "(PassengerId): missing values: 0\n",
      "(Pclass): missing values: 0\n",
      "(Name): missing values: 0\n",
      "(Sex): missing values: 0\n",
      "(Age): missing values: 86\n",
      "(SibSp): missing values: 0\n",
      "(Parch): missing values: 0\n",
      "(Ticket): missing values: 0\n",
      "(Fare): missing values: 1\n",
      "(Cabin): missing values: 327\n",
      "(Embarked): missing values: 0\n"
     ]
    }
   ],
   "source": [
    "## Load Data: \n",
    "# here in titanic competion, we have two sets of Datas: train, test\n",
    "\n",
    "df_train_path = '/home/vahid/Documents/ML_Learning/Titanic_Comp_kaggle/train.csv'\n",
    "df_test_path = '/home/vahid/Documents/ML_Learning/Titanic_Comp_kaggle/test.csv'\n",
    "\n",
    "df_train = pd.read_csv(df_train_path)\n",
    "df_train.name = 'Training Set'\n",
    "df_test = pd.read_csv(df_test_path)\n",
    "df_test.name = 'Test Set'\n",
    "df_data = pd.concat([df_train,df_test])\n",
    "df_data.name = 'All Data'\n",
    "print('train columns: ',df_train.columns,'\\n')\n",
    "\n",
    "# finding columns with missing values: \n",
    "def display_missing(df):\n",
    "    for col in df.columns:\n",
    "        print('({}): missing values: {}'.format(col, df[col].isnull().sum()))\n",
    "\n",
    "for df in [df_train, df_test]:\n",
    "    print('**Columns with Missing values of {}: '.format(df.name))\n",
    "    display_missing(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc5cc2d-e7a7-46c9-acca-b82e2d1fc5f2",
   "metadata": {},
   "source": [
    "# Missing_Values\n",
    "\n",
    "## Age: \n",
    "one of the important data here is the Age, and it has some missing values. \n",
    "How we refill these missing values is verey important. \n",
    "\n",
    "### replace missing values: \n",
    "I gess there is relationship between Title and Age. for example Capt dont refer to a child and so on. \n",
    "based on that my approach is: \n",
    "* extract titles from names. \n",
    "* classify titles. \n",
    "* group datas by title. \n",
    "* find median or mean of age based on grouped data. \n",
    "* fill the missing values by them. \n",
    "\n",
    "### Encoding: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ef166c3a-e315-4a53-83e0-72bc61f0fa8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Titles: \n",
      " ['Mr' 'Mrs' 'Miss' 'Master' 'Don' 'Rev' 'Dr' 'Mme' 'Ms' 'Major' 'Lady'\n",
      " 'Sir' 'Mlle' 'Col' 'Capt' 'Countess' 'Jonkheer' 'Dona']\n",
      "0 70.0\n",
      "1 54.5\n",
      "2 33.0\n",
      "3 40.0\n",
      "4 39.0\n",
      "5 46.5\n",
      "6 38.0\n",
      "7 48.0\n",
      "8 48.5\n",
      "9 6.0\n",
      "10 24.0\n",
      "11 24.0\n",
      "12 24.0\n",
      "13 34.5\n",
      "14 39.0\n",
      "15 38.25\n",
      "16 41.5\n",
      "17 49.0\n"
     ]
    }
   ],
   "source": [
    "## Missing Values : Age\n",
    "\n",
    "# Creating a new column called Title, \n",
    "# Extract the title from the name. \n",
    "for name_string in df_data['Name']: \n",
    "    df_data['Title'] = df_data['Name'].str.extract('([A-Za-z]+)\\.',expand=True)\n",
    "\n",
    "# Seeing All the titles we have. \n",
    "print('All Titles: \\n',df_data['Title'].unique())\n",
    "\n",
    "# Creat a temporary mapping dictionary: \n",
    "mapping = {'Dr':'Mr','Rev':'Mr','Mlle':'Miss','Major':'Mr','Col':'Mr',\n",
    "          'Sir':'Mr','Don':'Mr','Mme':'Miss','Jonkheer':'Mr','Lady':'Mrs',\n",
    "          'Capt':'Mr','Countess':'Mrs','Ms':'Miss','Dona':'Mrs',}\n",
    "#replacing Titles with new title in mapping dictionary: \n",
    "#df_data.replace({'Title':mapping},inplace=True)\n",
    "\n",
    "age_to_impute_median = df_data.groupby('Title')['Age'].median()\n",
    "age_to_impute_mean = df_data.groupby('Title')['Age'].mean()\n",
    "\n",
    "titles = ['Master', 'Miss', 'Mr', 'Mrs']\n",
    "All_Titles = list(df_data['Title'].unique())\n",
    "for title in All_Titles: \n",
    "    print(All_Titles.index(title), age_to_impute_median[All_Titles.index(title)])\n",
    "    df_data.loc[(df_data['Age'].isnull()) & (df_data['Title'] == title), 'Age'] = age_to_impute_median[All_Titles.index(title)]\n",
    "    \n",
    "df_train['Age'] = df_data['Age'][:891]   \n",
    "df_test['Age'] = df_data['Age'][891:]\n",
    "\n",
    "# discard the title as we no longer need it: \n",
    "df_data.drop('Title', axis = 1, inplace=True)\n",
    "\n",
    "#Binning Age\n",
    "df_data['AgeBin'] = pd.qcut(df_data['Age'],5)\n",
    "df_data['AgeBin'].head()\n",
    "\n",
    "label = LabelEncoder()\n",
    "\n",
    "df_data['AgeBin_Code'] = label.fit_transform(df_data['AgeBin'])\n",
    "df_train['AgeBin_Code'] = df_data['AgeBin_Code'][:891]\n",
    "df_test['AgeBin_Code'] = df_data['AgeBin_Code'][891:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5ef64c",
   "metadata": {},
   "source": [
    "## Family Survived: \n",
    "\n",
    "in the DataFrame we have two columns named 'Parch' and 'SibSp' which refer to number of parent/children \n",
    "and number of siblings/spouse. so the Family Size is sum of these two. \n",
    "\n",
    "the idea is: there are relationships between each person and his/her family survived. \n",
    "\n",
    "the Approach is: \n",
    "* find family size for each person. \n",
    "* find each family members. \n",
    "** by seperating family name from the name of a person and group the data by family name, we can find each family members.\n",
    "* find number of each family survived. \n",
    "* creat a column for these information. \n",
    "* make it one of the features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741fea41-7bb2-4dd5-94b8-a84680cdba70",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cbaf0108-482e-4909-95e9-024b58754f84",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Passengers with family survival data:  420\n",
      "Number of Passengers with family/Group survival data:  546\n"
     ]
    }
   ],
   "source": [
    "df_data['Family_Size'] = df_data['Parch'] + df_data['SibSp']\n",
    "df_train['Family_Size'] = df_data['Family_Size'][:891]\n",
    "df_test['Family_Size'] = df_data['Family_Size'][891:]\n",
    "\n",
    "df_data['Last_Name'] = df_data['Name'].apply(lambda x: str.split(x, \",\")[0])\n",
    "\n",
    "DEFAULT_SURVIVAL_VALUE = 0.5\n",
    "df_data['Family_Survived'] = DEFAULT_SURVIVAL_VALUE\n",
    "\n",
    "for grp, grp_df in df_data[['Survived','Name', 'Last_Name', 'Fare',\n",
    "                            'Ticket', 'PassengerId','Parch','SibSp',\n",
    "                            'Age', 'Cabin']].groupby(['Last_Name', 'Fare']):\n",
    "    if (len(grp_df) != 1):\n",
    "        for ind , row in grp_df.iterrows():\n",
    "            smax = grp_df.drop(ind)['Survived'].max()\n",
    "            smin = grp_df.drop(ind)['Survived'].min()\n",
    "            passID = row['PassengerId']\n",
    "            if (smax == 1.0):\n",
    "                df_data.loc[df_data[\"PassengerId\"] == passID, 'Family_Survived'] = 1\n",
    "            elif (smin == 0.0):\n",
    "                df_data.loc[df_data[\"PassengerId\"] == passID, 'Family_Survived'] = 0\n",
    "  \n",
    "print(\"Number of Passengers with family survival data: \",\n",
    "     df_data.loc[df_data['Family_Survived'] !=0.5].shape[0])\n",
    "           \n",
    "    \n",
    "for grp ,grp_df in df_data.groupby('Ticket'): \n",
    "    if (len(grp_df) != 1):\n",
    "        for ind , row in grp_df.iterrows():\n",
    "            if (row['Family_Survived'] == 0 or row['Family_Survived'] == 0.5):\n",
    "                smax = grp_df.drop(ind)['Survived'].max()\n",
    "                smin = grp_df.drop(ind)['Survived'].min()\n",
    "                passID = row['PassengerId']\n",
    "                if (smax == 1): \n",
    "                    df_data.loc[df_data[\"PassengerId\"] == passID, 'Family_Survived'] = 1\n",
    "                elif (smin == 0.0):\n",
    "                    df_data.loc[df_data[\"PassengerId\"] == passID, 'Family_Survived'] = 0\n",
    "                    \n",
    "print(\"Number of Passengers with family/Group survival data: \",\n",
    "     df_data.loc[df_data['Family_Survived'] !=0.5].shape[0])  \n",
    "\n",
    "df_train['Family_Survived'] = df_data['Family_Survived'][:891]\n",
    "df_test['Family_Survived'] = df_data['Family_Survived'][891:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a410a9db-156e-4fea-a023-d57d4d1bb362",
   "metadata": {},
   "source": [
    "## Fare Column: \n",
    "\n",
    "fare column consists of null values. besides that, range of values is wide and we need to encode values. \n",
    "so, at first we need to fill null values and then encoding values. \n",
    "\n",
    "for filling null values, the logical way may be using Pclass column. for that, group data by Pclass column and get the median of ech group. \n",
    "and then replace the missing values by that. \n",
    "\n",
    "after that, we need to encode velues. we can splite values to for example 5 interval and then attributiong a label to them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c539d5bb-d982-4d70-b584-7f1886b39289",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 60.0\n",
      "1 15.0458\n",
      "2 8.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7351/3178404276.py:17: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df_train.drop(['Fare'], 1, inplace=True)\n",
      "/tmp/ipykernel_7351/3178404276.py:18: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df_test.drop(['Fare'], 1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "fare_to_impute = df_data.groupby('Pclass')['Fare'].median()\n",
    "pclasses = [3,1,2]\n",
    "\n",
    "for pcls in pclasses: \n",
    "    print(pclasses.index(pcls),fare_to_impute[pclasses.index(pcls)+1])\n",
    "    df_data.loc[(df_data['Fare'].isnull()) & (df_data['Pclass'] == pcls), 'Fare'] = fare_to_impute[pclasses.index(pcls)+1]\n",
    "    \n",
    "    \n",
    "df_data['FareBin'] = pd.qcut(df_data['Fare'],5)\n",
    "\n",
    "label = LabelEncoder()\n",
    "df_data['FareBin_Code'] = label.fit_transform(df_data['FareBin'])\n",
    "df_train['FareBin_Code'] = df_data['FareBin_Code'][:891]\n",
    "df_test['FareBin_Code'] = df_data['FareBin_Code'][891:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "513183a7-52ea-473f-8efc-34b0fadde33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Family_Survived</th>\n",
       "      <th>FareBin_Code</th>\n",
       "      <th>AgeBin_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>3</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name  Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    0  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...    3  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina    3  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)    3  35.0      1   \n",
       "4                             Allen, Mr. William Henry    0  35.0      0   \n",
       "..                                                 ...  ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    0  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith    3  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"    3  33.0      1   \n",
       "889                              Behr, Mr. Karl Howell    0  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    0  32.0      0   \n",
       "\n",
       "     Parch            Ticket Cabin Embarked  Family_Size  Family_Survived  \\\n",
       "0        0         A/5 21171   NaN        S            1              0.5   \n",
       "1        0          PC 17599   C85        C            1              0.5   \n",
       "2        0  STON/O2. 3101282   NaN        S            0              0.5   \n",
       "3        0            113803  C123        S            1              0.0   \n",
       "4        0            373450   NaN        S            0              0.5   \n",
       "..     ...               ...   ...      ...          ...              ...   \n",
       "886      0            211536   NaN        S            0              0.5   \n",
       "887      0            112053   B42        S            0              0.5   \n",
       "888      2        W./C. 6607   NaN        S            3              0.0   \n",
       "889      0            111369  C148        C            0              0.5   \n",
       "890      0            370376   NaN        Q            0              0.5   \n",
       "\n",
       "     FareBin_Code  AgeBin_Code  \n",
       "0               0            1  \n",
       "1               4            3  \n",
       "2               1            1  \n",
       "3               4            2  \n",
       "4               1            2  \n",
       "..            ...          ...  \n",
       "886             2            1  \n",
       "887             3            0  \n",
       "888             3            2  \n",
       "889             3            1  \n",
       "890             0            2  \n",
       "\n",
       "[891 rows x 15 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mapping sex to code and then clean up any unnecessary stuff\n",
    "df_train.Sex[(df_train['Age'] < 16) ] = 'Child'\n",
    "df_test.Sex[(df_test['Age'] < 16)] = 'Child'\n",
    "df_train.Sex.unique()\n",
    "df_train['Sex'].replace(['male','female','Child'],[0,3,6],inplace=True)\n",
    "df_test['Sex'].replace(['male','female','Child'],[0,3,6],inplace =True)\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934a3609-eefe-431b-810d-bd4c3e1619e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping unneccessary columns: \n",
    "\n",
    "#Discard the raw fare data as it is no longer useful\n",
    "df_train.drop(['Fare'], 1, inplace=True)\n",
    "df_test.drop(['Fare'], 1, inplace=True)\n",
    "\n",
    "#Drop the original age feature from the dataset\n",
    "df_train.drop(['Age'], 1, inplace=True)\n",
    "df_test.drop(['Age'], 1, inplace=True)\n",
    "\n",
    "#dropping a whole bunch of unused featureds\n",
    "df_train.drop(['Name', 'PassengerId', 'SibSp', 'Parch', 'Ticket', 'Cabin',\n",
    "               'Embarked'], axis = 1, inplace = True)\n",
    "df_test.drop(['Name','PassengerId', 'SibSp', 'Parch', 'Ticket', 'Cabin',\n",
    "              'Embarked'], axis = 1, inplace = True)\n",
    "train_df.columns\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e99ed2ad-8387-4ba6-8905-0899d3440502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Columns with Missing values of Training Set: \n",
      "(PassengerId): missing values: 0\n",
      "(Survived): missing values: 0\n",
      "(Pclass): missing values: 0\n",
      "(Name): missing values: 0\n",
      "(Sex): missing values: 0\n",
      "(Age): missing values: 0\n",
      "(SibSp): missing values: 0\n",
      "(Parch): missing values: 0\n",
      "(Ticket): missing values: 0\n",
      "(Fare): missing values: 0\n",
      "(Cabin): missing values: 687\n",
      "(Embarked): missing values: 2\n",
      "**Columns with Missing values of Test Set: \n",
      "(PassengerId): missing values: 0\n",
      "(Pclass): missing values: 0\n",
      "(Name): missing values: 0\n",
      "(Sex): missing values: 0\n",
      "(Age): missing values: 0\n",
      "(SibSp): missing values: 0\n",
      "(Parch): missing values: 0\n",
      "(Ticket): missing values: 0\n",
      "(Fare): missing values: 1\n",
      "(Cabin): missing values: 327\n",
      "(Embarked): missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# finding columns with missing values: \n",
    "def display_missing(df):\n",
    "    for col in df.columns:\n",
    "        print('({}): missing values: {}'.format(col, df[col].isnull().sum()))\n",
    "\n",
    "for df in [df_train, df_test]:\n",
    "    print('**Columns with Missing values of {}: '.format(df.name))\n",
    "    display_missing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "341ad083-35dc-45aa-8b79-3901492eb9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtaining target(dependent variable) and predictors(independent variable): \n",
    "y = df_train.Survived\n",
    "features_1 = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "features_2 = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',]\n",
    "features_3 = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin']\n",
    "\n",
    "X = df_train[features_2].copy()\n",
    "X_test = df_test[features_2].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd9e4dee-612c-4264-a82b-49e71d0655d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make Sex column numerical. \n",
    "\n",
    "temp_Sex_X = pd.get_dummies(X['Sex'])\n",
    "X['Sex_F'] = temp_Sex_X['female']\n",
    "X['Sex_M'] = temp_Sex_X['male']\n",
    "X.drop('Sex',inplace=True, axis=1)\n",
    "\n",
    "temp_Sex_X_test = pd.get_dummies(X_test['Sex'])\n",
    "X_test['Sex_F'] = temp_Sex_X_test['female']\n",
    "X_test['Sex_M'] = temp_Sex_X_test['male']\n",
    "X_test.drop('Sex',inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72aad5bc-a864-49ca-bcac-98d413aa1654",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Missing values: \n",
    "\n",
    "# here, for missing values I used simpleImputer:\n",
    "# Imputer for train datas: \n",
    "my_imputer = SimpleImputer()\n",
    "\n",
    "imputed_X = pd.DataFrame(my_imputer.fit_transform(X))\n",
    "imputed_X_test = pd.DataFrame(my_imputer.transform(X_test))\n",
    "\n",
    "# Imputation removed column names; put them back: \n",
    "imputed_X.columns = X.columns\n",
    "imputed_X_test.columns = X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4edb27b-0f5b-41d5-8d7e-595297f2f3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_M</th>\n",
       "      <th>conv_Age</th>\n",
       "      <th>conv_Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  SibSp  Parch  Sex_F  Sex_M  conv_Age  conv_Fare\n",
       "0     3.0    0.0    0.0    0.0    1.0         9          0\n",
       "1     3.0    1.0    0.0    1.0    0.0        12          0\n",
       "2     2.0    0.0    0.0    0.0    1.0        16          0\n",
       "3     3.0    0.0    0.0    0.0    1.0         7          0\n",
       "4     3.0    1.0    1.0    1.0    0.0         5          0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## I have sets of data that are continiuous and make prediction continuous. \n",
    "## I want to put them in specified classes tp avoid this problem. \n",
    "\n",
    "\n",
    "X_ImpConv = imputed_X.copy()\n",
    "X_test_ImpConv = imputed_X_test.copy()\n",
    "\n",
    "# defining a function for classifing data:\n",
    "def my_converter(data_series, num_clas):\n",
    "    first_list = list(data_series)\n",
    "    conved_list = list()\n",
    "    len_clas = (max(first_list) - min(first_list))/num_clas\n",
    "    for i in range(len(first_list)): \n",
    "        botm_bound = 0\n",
    "        uper_bound = len_clas\n",
    "        for k in range(num_clas+1): \n",
    "            if first_list[i] >= botm_bound and first_list[i] < uper_bound:\n",
    "                conved_list.append(k)\n",
    "                break\n",
    "            else: \n",
    "                botm_bound = botm_bound + len_clas\n",
    "                uper_bound = uper_bound + len_clas\n",
    "    return conved_list\n",
    "                \n",
    "    \n",
    "## for Age and Fare I want to use this converter to classifying them.    \n",
    "# defining new columns named conv_Age and conv_Fare. \n",
    "X_ImpConv['conv_Age'] = my_converter(imputed_X.Age,20)\n",
    "X_ImpConv['conv_Fare'] = my_converter(imputed_X.Fare,20)\n",
    "\n",
    "X_test_ImpConv['conv_Age'] = my_converter(imputed_X_test.Age,20)\n",
    "X_test_ImpConv['conv_Fare'] = my_converter(imputed_X_test.Fare,20)\n",
    "\n",
    "# dropping the original columns for Age and Fare. \n",
    "X_ImpConv.drop('Age',inplace=True, axis=1)\n",
    "X_ImpConv.drop('Fare',inplace=True, axis=1)\n",
    "\n",
    "X_test_ImpConv.drop('Age',inplace=True, axis=1)\n",
    "X_test_ImpConv.drop('Fare',inplace=True, axis=1)\n",
    "\n",
    "\n",
    "X_test_ImpConv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918c635a-4205-42f1-b931-7936b05ae3af",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f361e8e3-257e-41ad-96a8-a81354022faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique values of Pclass column:  3\n",
      "unique values of Pclass column:  [3, 1, 2]\n",
      "% of Pclass_1 who survived: 0.6296296296296297\n",
      "% of Pclass_2 who survived: 0.47282608695652173\n",
      "% of Pclass_3 who survived: 0.24236252545824846\n"
     ]
    }
   ],
   "source": [
    "## I want to know if Pclass is the good feature to consider??\n",
    "    \n",
    "plt.scatter(df_train.Pclass, y)\n",
    "plt.show()\n",
    "\n",
    "print(\"number of unique values of Pclass column: \",df_train.Pclass.nunique())\n",
    "print(\"unique values of Pclass column: \",list(df_train.Pclass.unique()))\n",
    "\n",
    "Pclass_1 = df_train.loc[df_train.Pclass == 1][\"Survived\"]\n",
    "rate_Pclass_1 = sum(Pclass_1)/len(Pclass_1)\n",
    "print(\"% of Pclass_1 who survived:\", rate_Pclass_1)\n",
    "\n",
    "Pclass_2 = df_train.loc[df_train.Pclass == 2][\"Survived\"]\n",
    "rate_Pclass_2 = sum(Pclass_2)/len(Pclass_2)\n",
    "print(\"% of Pclass_2 who survived:\", rate_Pclass_2)\n",
    "\n",
    "Pclass_3 = df_train.loc[df_train.Pclass == 3][\"Survived\"]\n",
    "rate_Pclass_3 = sum(Pclass_3)/len(Pclass_3)\n",
    "print(\"% of Pclass_3 who survived:\", rate_Pclass_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "617eca31-423d-47f5-baa6-b449e3ffd666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique values of Age_class column:  20\n",
      "unique values of Age_class column:  [5, 9, 6, 8, 7, 13, 0, 3, 1, 14, 2, 4, 10, 16, 12, 11, 17, 15, 20, 18]\n",
      "% of Age_clas_1 who survived: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## I want to know if Age is the good feature to consider??\n",
    "\n",
    "temp_X_ImpConv = X_ImpConv.copy()\n",
    "temp_X_ImpConv[\"Survived\"] = y\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "    \n",
    "plt.scatter(temp_X_ImpConv.conv_Age, y)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"number of unique values of Age_class column: \",temp_X_ImpConv.conv_Age.nunique())\n",
    "print(\"unique values of Age_class column: \",list(temp_X_ImpConv.conv_Age.unique()))\n",
    "\n",
    "Age_clas_1 = temp_X_ImpConv.loc[temp_X_ImpConv.conv_Age == 20][\"Survived\"]\n",
    "rate_Age_clas_1 = sum(Age_clas_1)/len(Age_clas_1)\n",
    "print(\"% of Age_clas_1 who survived:\", rate_Age_clas_1)\n",
    "len(Age_clas_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e0b499bc-6860-4311-8a51-ed8d6c7fb0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique values of SibSp column:  7\n",
      "unique values of SibSp column:  [1, 0, 3, 4, 2, 5, 8]\n",
      "percentage of 209 member of SibSp 1 who survived: 0.535885: \n",
      "percentage of 608 member of SibSp 0 who survived: 0.345395: \n",
      "percentage of 16 member of SibSp 3 who survived: 0.250000: \n",
      "percentage of 18 member of SibSp 4 who survived: 0.166667: \n",
      "percentage of 28 member of SibSp 2 who survived: 0.464286: \n",
      "percentage of 5 member of SibSp 5 who survived: 0.000000: \n",
      "percentage of 7 member of SibSp 8 who survived: 0.000000: \n"
     ]
    }
   ],
   "source": [
    "print(\"number of unique values of SibSp column: \",df_train.SibSp.nunique())\n",
    "print(\"unique values of SibSp column: \",list(df_train.SibSp.unique()))\n",
    "\n",
    "for i in range(len(df_train.SibSp.unique())): \n",
    "    SibSp = df_train.loc[df_train.SibSp == df_train.SibSp.unique()[i]][\"Survived\"]\n",
    "    rate_SibSp = sum(SibSp)/len(SibSp)\n",
    "    print(\"percentage of %d member of SibSp %d who survived: %f: \" % (len(SibSp),df_train.SibSp.unique()[i],rate_SibSp)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7952103e-0f49-44f9-b3e5-2427a2847fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique values of Parch column:  7\n",
      "unique values of Parch column:  [0, 1, 2, 5, 3, 4, 6]\n",
      "percentage of 678 member of Parch 0 who survived: 0.343658: \n",
      "percentage of 118 member of Parch 1 who survived: 0.550847: \n",
      "percentage of 80 member of Parch 2 who survived: 0.500000: \n",
      "percentage of 5 member of Parch 5 who survived: 0.200000: \n",
      "percentage of 5 member of Parch 3 who survived: 0.600000: \n",
      "percentage of 4 member of Parch 4 who survived: 0.000000: \n",
      "percentage of 1 member of Parch 6 who survived: 0.000000: \n"
     ]
    }
   ],
   "source": [
    "print(\"number of unique values of Parch column: \",df_train.Parch.nunique())\n",
    "print(\"unique values of Parch column: \",list(df_train.Parch.unique()))\n",
    "\n",
    "for i in range(len(df_train.Parch.unique())): \n",
    "    Parch = df_train.loc[df_train.Parch == df_train.Parch.unique()[i]][\"Survived\"]\n",
    "    rate_Parch = sum(Parch)/len(Parch)\n",
    "    print(\"percentage of %d member of Parch %d who survived: %f: \" % (len(Parch),df_train.Parch.unique()[i],rate_Parch))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "16333eab-4020-427b-82fa-b40aac520406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique values of conv_Fare column:  11\n",
      "unique values of conv_Fare column:  [0, 2, 1, 10, 5, 3, 9, 4, 19, 6, 8]\n",
      "percentage of 562 member of SibSp 0 who survived: 0.284698: \n",
      "percentage of 67 member of SibSp 2 who survived: 0.597015: \n",
      "percentage of 170 member of SibSp 1 who survived: 0.429412: \n",
      "percentage of 6 member of SibSp 10 who survived: 0.666667: \n",
      "percentage of 16 member of SibSp 5 who survived: 0.750000: \n",
      "percentage of 39 member of SibSp 3 who survived: 0.769231: \n",
      "percentage of 2 member of SibSp 9 who survived: 0.500000: \n",
      "percentage of 15 member of SibSp 4 who survived: 0.733333: \n",
      "percentage of 3 member of SibSp 19 who survived: 1.000000: \n",
      "percentage of 2 member of SibSp 6 who survived: 1.000000: \n",
      "percentage of 9 member of SibSp 8 who survived: 0.666667: \n"
     ]
    }
   ],
   "source": [
    "temp_X_ImpConv = X_ImpConv.copy()\n",
    "temp_X_ImpConv[\"Survived\"] = y\n",
    "\n",
    "print(\"number of unique values of conv_Fare column: \",temp_X_ImpConv.conv_Fare.nunique())\n",
    "print(\"unique values of conv_Fare column: \",list(temp_X_ImpConv.conv_Fare.unique()))\n",
    "\n",
    "for i in range(len(temp_X_ImpConv.conv_Fare.unique())): \n",
    "    conv_Fare = temp_X_ImpConv.loc[temp_X_ImpConv.conv_Fare == temp_X_ImpConv.conv_Fare.unique()[i]][\"Survived\"]\n",
    "    rate_conv_Fare = sum(conv_Fare)/len(conv_Fare)\n",
    "    print(\"percentage of %d member of SibSp %d who survived: %f: \" % (len(conv_Fare),temp_X_ImpConv.conv_Fare.unique()[i],rate_conv_Fare)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa89feb-1318-45d5-88d1-53582e2cfb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X[])\n",
    "X_test = pd.get_dummies(test_data[features])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
